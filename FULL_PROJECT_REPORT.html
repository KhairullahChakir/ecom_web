
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>OP-ECOM Project Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 40px;
            color: #333;
            background: #fff;
        }
        h1 {
            color: #1E4FA8;
            border-bottom: 3px solid #1E4FA8;
            padding-bottom: 10px;
            font-size: 2em;
        }
        h2 {
            color: #2563EB;
            border-bottom: 1px solid #ddd;
            padding-bottom: 5px;
            margin-top: 30px;
            font-size: 1.5em;
        }
        h3 {
            color: #3B82F6;
            font-size: 1.2em;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
            font-size: 0.9em;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #1E4FA8;
            color: white;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Consolas', 'Courier New', monospace;
            font-size: 0.9em;
        }
        pre {
            background-color: #1a1a2e;
            color: #eee;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85em;
        }
        pre code {
            background-color: transparent;
            color: inherit;
            padding: 0;
        }
        blockquote {
            border-left: 4px solid #1E4FA8;
            margin: 20px 0;
            padding: 10px 20px;
            background-color: #f8f9fa;
        }
        hr {
            border: none;
            border-top: 2px solid #1E4FA8;
            margin: 30px 0;
        }
        strong {
            color: #1E4FA8;
        }
        .print-instructions {
            background: linear-gradient(135deg, #1E4FA8, #3B82F6);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            text-align: center;
        }
        .print-instructions h3 {
            color: white;
            margin: 0 0 10px 0;
        }
        @media print {
            .print-instructions {
                display: none;
            }
            body {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="print-instructions">
        <h3>ğŸ“„ To Export as PDF:</h3>
        <p>Press <strong>Ctrl + P</strong> â†’ Select "Save as PDF" â†’ Click Save</p>
    </div>
    <h1 id="op-ecom-complete-technical-report">OP-ECOM: Complete Technical Report</h1>
<h2 id="real-time-purchase-intent-prediction-system-with-self-hosted-analytics">Real-Time Purchase Intent Prediction System with Self-Hosted Analytics</h2>
<p><strong>Author</strong>: Developed with AI Assistance (Antigravity)<br />
<strong>Date</strong>: January 29, 2026<br />
<strong>Hardware</strong>: Intel(R) Core(TM) i7-1165G7 @ 2.80GHz<br />
<strong>Stack</strong>: Python, FastAPI, ONNX Runtime, MariaDB, Next.js, Vite  </p>
<hr />
<h2 id="executive-summary">Executive Summary</h2>
<p>OP-ECOM is a complete end-to-end machine learning system for predicting online shopper purchase intent. The project demonstrates the full ML lifecycle: from data preprocessing and model training, through optimization and deployment, to real-time analytics collection. The system achieves <strong>sub-millisecond inference latency</strong> while maintaining high prediction accuracy.</p>
<p><strong>Key Achievements:</strong>
- ğŸ¯ <strong>0.923 AUC-ROC</strong> with TabM deep learning model
- âš¡ <strong>0.31ms inference latency</strong> using ONNX optimization
- ğŸ“Š <strong>Self-hosted analytics</strong> tracking real user behavior
- ğŸŒ <strong>Full-stack deployment</strong> with Next.js frontend and FastAPI backend</p>
<hr />
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#1-problem-statement">Problem Statement</a></li>
<li><a href="#2-dataset--preprocessing">Dataset &amp; Preprocessing</a></li>
<li><a href="#3-model-development">Model Development</a></li>
<li><a href="#4-model-optimization">Model Optimization</a></li>
<li><a href="#5-backend-architecture">Backend Architecture</a></li>
<li><a href="#6-frontend-application">Frontend Application</a></li>
<li><a href="#7-analytics-tracker-system">Analytics Tracker System</a></li>
<li><a href="#8-performance-benchmarks">Performance Benchmarks</a></li>
<li><a href="#9-deployment-guide">Deployment Guide</a></li>
<li><a href="#10-future-work">Future Work</a></li>
<li><a href="#11-conclusion">Conclusion</a></li>
</ol>
<hr />
<h2 id="1-problem-statement">1. Problem Statement</h2>
<h3 id="11-business-context">1.1 Business Context</h3>
<p>E-commerce platforms need to identify users likely to make a purchase in real-time to:
- Personalize product recommendations
- Target high-intent users with promotions
- Optimize marketing spend
- Improve conversion rates</p>
<h3 id="12-technical-challenge">1.2 Technical Challenge</h3>
<p>Deep learning models often achieve high accuracy but at the cost of:
- High computational latency (&gt;100ms)
- Complex deployment requirements
- Inability to run on CPU-only infrastructure</p>
<h3 id="13-project-objectives">1.3 Project Objectives</h3>
<table>
<thead>
<tr>
<th>Objective</th>
<th>Target</th>
<th>Achievement</th>
</tr>
</thead>
<tbody>
<tr>
<td>Prediction Accuracy</td>
<td>AUC &gt; 0.85</td>
<td>âœ… 0.923</td>
</tr>
<tr>
<td>Inference Latency</td>
<td>&lt; 10ms</td>
<td>âœ… 0.31ms</td>
</tr>
<tr>
<td>Precision (Business)</td>
<td>&gt; 0.60</td>
<td>âœ… 0.667</td>
</tr>
<tr>
<td>Real-time Capable</td>
<td>Yes</td>
<td>âœ… Sub-ms</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-dataset-preprocessing">2. Dataset &amp; Preprocessing</h2>
<h3 id="21-data-source">2.1 Data Source</h3>
<p><strong>UCI Online Shoppers Purchasing Intention Dataset</strong>
- <strong>Origin</strong>: UCI Machine Learning Repository
- <strong>Total Samples</strong>: 12,330 user sessions
- <strong>Features</strong>: 17 input features + 1 target
- <strong>Class Imbalance</strong>: ~15% positive (Revenue=TRUE)</p>
<h3 id="22-feature-description">2.2 Feature Description</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Feature</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Behavioral</strong></td>
<td>Administrative</td>
<td>Integer</td>
<td>Admin pages visited</td>
</tr>
<tr>
<td></td>
<td>Administrative_Duration</td>
<td>Float</td>
<td>Time on admin pages (seconds)</td>
</tr>
<tr>
<td></td>
<td>Informational</td>
<td>Integer</td>
<td>Info pages visited</td>
</tr>
<tr>
<td></td>
<td>Informational_Duration</td>
<td>Float</td>
<td>Time on info pages</td>
</tr>
<tr>
<td></td>
<td>ProductRelated</td>
<td>Integer</td>
<td>Product pages visited</td>
</tr>
<tr>
<td></td>
<td>ProductRelated_Duration</td>
<td>Float</td>
<td>Time on product pages</td>
</tr>
<tr>
<td></td>
<td>BounceRates</td>
<td>Float</td>
<td>% of single-page sessions</td>
</tr>
<tr>
<td></td>
<td>ExitRates</td>
<td>Float</td>
<td>% of exits from pages</td>
</tr>
<tr>
<td></td>
<td>PageValues</td>
<td>Float</td>
<td>Avg value of pages viewed</td>
</tr>
<tr>
<td><strong>Temporal</strong></td>
<td>SpecialDay</td>
<td>Float</td>
<td>Proximity to special day (0-1)</td>
</tr>
<tr>
<td></td>
<td>Month</td>
<td>Categorical</td>
<td>Month of visit</td>
</tr>
<tr>
<td></td>
<td>Weekend</td>
<td>Boolean</td>
<td>Weekend visit</td>
</tr>
<tr>
<td><strong>Technical</strong></td>
<td>OperatingSystems</td>
<td>Integer</td>
<td>OS category ID</td>
</tr>
<tr>
<td></td>
<td>Browser</td>
<td>Integer</td>
<td>Browser category ID</td>
</tr>
<tr>
<td></td>
<td>Region</td>
<td>Integer</td>
<td>Geographic region ID</td>
</tr>
<tr>
<td></td>
<td>TrafficType</td>
<td>Integer</td>
<td>Traffic source ID</td>
</tr>
<tr>
<td></td>
<td>VisitorType</td>
<td>Categorical</td>
<td>New/Returning/Other</td>
</tr>
<tr>
<td><strong>Target</strong></td>
<td>Revenue</td>
<td>Boolean</td>
<td>Purchase made</td>
</tr>
</tbody>
</table>
<h3 id="23-data-split-strategy">2.3 Data Split Strategy</h3>
<p>To ensure reproducibility and prevent data leakage:</p>
<pre><code class="language-python"># Stratified 70/10/20 split with fixed seed
from sklearn.model_selection import train_test_split

X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp
)
</code></pre>
<table>
<thead>
<tr>
<th>Split</th>
<th>Samples</th>
<th>Percentage</th>
</tr>
</thead>
<tbody>
<tr>
<td>Training</td>
<td>8,631</td>
<td>70%</td>
</tr>
<tr>
<td>Validation</td>
<td>1,233</td>
<td>10%</td>
</tr>
<tr>
<td>Testing</td>
<td>2,466</td>
<td>20%</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>12,330</strong></td>
<td><strong>100%</strong></td>
</tr>
</tbody>
</table>
<h3 id="24-preprocessing-pipeline">2.4 Preprocessing Pipeline</h3>
<pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])
</code></pre>
<p><strong>Numerical Features</strong>: StandardScaler normalization<br />
<strong>Categorical Features</strong>: OneHotEncoder (Month, VisitorType)<br />
<strong>Output Dimensions</strong>: 65 features after encoding</p>
<hr />
<h2 id="3-model-development">3. Model Development</h2>
<h3 id="31-baseline-models">3.1 Baseline Models</h3>
<p>Three baseline models were trained for comparison:</p>
<h4 id="logistic-regression">Logistic Regression</h4>
<pre><code class="language-python">from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression(max_iter=1000, C=0.1)
</code></pre>
<h4 id="xgboost-gradient-boosting">XGBoost (Gradient Boosting)</h4>
<pre><code class="language-python">import xgboost as xgb
xgb_model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    use_label_encoder=False
)
</code></pre>
<h3 id="32-tabm-architecture">3.2 TabM Architecture</h3>
<p><strong>TabM</strong> (Tabular Model with Multiplicative Networks) was selected as the primary model due to its:
- Superior performance on tabular data
- Efficient ensemble mechanism
- GPU-optional training</p>
<h4 id="architecture-diagram">Architecture Diagram</h4>
<pre><code>Input Layer (65 features after preprocessing)
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚  Embedding  â”‚  (d=64 per feature)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚ BatchNorm   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Batch Ensemble Block  â”‚
    â”‚   K=16 parallel MLPs    â”‚
    â”‚   Each: 128â†’64â†’32â†’1     â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚  Averaging  â”‚  (Mean of K outputs)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â†“
    Sigmoid â†’ Probability [0, 1]
</code></pre>
<h4 id="key-hyperparameters">Key Hyperparameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>d_embedding</code></td>
<td>64</td>
<td>Feature embedding dimension</td>
</tr>
<tr>
<td><code>n_blocks</code></td>
<td>3</td>
<td>Network depth</td>
</tr>
<tr>
<td><code>ensemble_size</code></td>
<td>16 (â†’4 pruned)</td>
<td>Parallel sub-networks</td>
</tr>
<tr>
<td><code>hidden_dim</code></td>
<td>128</td>
<td>MLP hidden size</td>
</tr>
<tr>
<td><code>dropout</code></td>
<td>0.15</td>
<td>Regularization</td>
</tr>
<tr>
<td><code>learning_rate</code></td>
<td>0.001</td>
<td>Adam optimizer</td>
</tr>
<tr>
<td><code>epochs</code></td>
<td>100</td>
<td>With early stopping</td>
</tr>
</tbody>
</table>
<h3 id="33-training-process">3.3 Training Process</h3>
<pre><code class="language-python"># Training loop with early stopping
best_val_auc = 0
patience = 10
patience_counter = 0

for epoch in range(100):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        outputs = model(batch['features'])
        loss = criterion(outputs, batch['labels'])
        loss.backward()
        optimizer.step()

    # Validation
    val_auc = evaluate(model, val_loader)
    if val_auc &gt; best_val_auc:
        best_val_auc = val_auc
        torch.save(model.state_dict(), 'best_model.pt')
        patience_counter = 0
    else:
        patience_counter += 1
        if patience_counter &gt;= patience:
            break
</code></pre>
<hr />
<h2 id="4-model-optimization">4. Model Optimization</h2>
<h3 id="41-ensemble-pruning">4.1 Ensemble Pruning</h3>
<p>Large ensemble sizes increase accuracy but also latency. We conducted an ablation study:</p>
<table>
<thead>
<tr>
<th>Ensemble Size</th>
<th>AUC-ROC</th>
<th>Mean Latency</th>
<th>p95 Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td>16</td>
<td>0.894</td>
<td>3.21ms</td>
<td>5.08ms</td>
</tr>
<tr>
<td>12</td>
<td>0.893</td>
<td>2.45ms</td>
<td>3.89ms</td>
</tr>
<tr>
<td>8</td>
<td>0.896</td>
<td>1.89ms</td>
<td>2.89ms</td>
</tr>
<tr>
<td><strong>4 (Selected)</strong></td>
<td><strong>0.898</strong></td>
<td><strong>0.89ms</strong></td>
<td><strong>1.38ms</strong></td>
</tr>
<tr>
<td>2</td>
<td>0.895</td>
<td>0.45ms</td>
<td>0.71ms</td>
</tr>
</tbody>
</table>
<p><strong>Optimal Point</strong>: Ensemble size 4 achieved the best accuracy with acceptable latency.</p>
<h3 id="42-onnx-export">4.2 ONNX Export</h3>
<p>Converting PyTorch to ONNX provided significant speedup:</p>
<pre><code class="language-python">import torch.onnx

# Export model
torch.onnx.export(
    model,
    torch.randn(1, 65),  # Dummy input
    &quot;tabm_model.onnx&quot;,
    input_names=['features'],
    output_names=['probability'],
    dynamic_axes={'features': {0: 'batch_size'}},
    opset_version=14
)
</code></pre>
<h4 id="speed-comparison">Speed Comparison</h4>
<table>
<thead>
<tr>
<th>Runtime</th>
<th>Mean Latency</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>PyTorch (CPU)</td>
<td>1.38ms</td>
<td>1.0x</td>
</tr>
<tr>
<td><strong>ONNX Runtime</strong></td>
<td><strong>0.31ms</strong></td>
<td><strong>4.4x</strong></td>
</tr>
</tbody>
</table>
<h3 id="43-final-model-metrics">4.3 Final Model Metrics</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AUC-ROC</strong></td>
<td>0.923</td>
<td>Excellent discrimination</td>
</tr>
<tr>
<td><strong>Precision</strong></td>
<td>0.667</td>
<td>2/3 predictions correct</td>
</tr>
<tr>
<td><strong>Recall</strong></td>
<td>0.636</td>
<td>Catches 64% of buyers</td>
</tr>
<tr>
<td><strong>F1-Score</strong></td>
<td>0.651</td>
<td>Balanced performance</td>
</tr>
<tr>
<td><strong>PR-AUC</strong></td>
<td>0.676</td>
<td>Good on imbalanced data</td>
</tr>
<tr>
<td><strong>Brier Score</strong></td>
<td>0.080</td>
<td>Well-calibrated probabilities</td>
</tr>
</tbody>
</table>
<h3 id="44-precisiontopk-business-metric">4.4 Precision@TopK (Business Metric)</h3>
<table>
<thead>
<tr>
<th>Top K%</th>
<th>Precision</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Top 5%</td>
<td><strong>88.62%</strong></td>
<td>Premium targeting</td>
</tr>
<tr>
<td>Top 10%</td>
<td>73.98%</td>
<td>Broad campaigns</td>
</tr>
<tr>
<td>Top 20%</td>
<td>61.45%</td>
<td>General outreach</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="5-backend-architecture">5. Backend Architecture</h2>
<h3 id="51-prediction-api-fastapi">5.1 Prediction API (FastAPI)</h3>
<p><strong>Location</strong>: <code>d:\op_ecom\backend\</code><br />
<strong>Port</strong>: 8000</p>
<h4 id="file-structure">File Structure</h4>
<pre><code>backend/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py          # FastAPI application
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tabm_best.onnx   # Optimized model
â”‚   â””â”€â”€ preprocessor.joblib  # Sklearn pipeline
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_predict.py  # API tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
</code></pre>
<h4 id="api-endpoints">API Endpoints</h4>
<table>
<thead>
<tr>
<th>Endpoint</th>
<th>Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>/</code></td>
<td>GET</td>
<td>Service info</td>
</tr>
<tr>
<td><code>/health</code></td>
<td>GET</td>
<td>Health check</td>
</tr>
<tr>
<td><code>/predict</code></td>
<td>POST</td>
<td>Make prediction</td>
</tr>
</tbody>
</table>
<h4 id="requestresponse-schema">Request/Response Schema</h4>
<p><strong>Request</strong>:</p>
<pre><code class="language-json">{
  &quot;administrative&quot;: 0,
  &quot;administrative_duration&quot;: 0.0,
  &quot;informational&quot;: 0,
  &quot;informational_duration&quot;: 0.0,
  &quot;product_related&quot;: 35,
  &quot;product_related_duration&quot;: 1200.5,
  &quot;bounce_rates&quot;: 0.02,
  &quot;exit_rates&quot;: 0.04,
  &quot;page_values&quot;: 12.5,
  &quot;special_day&quot;: 0.0,
  &quot;month&quot;: &quot;Nov&quot;,
  &quot;operating_systems&quot;: 2,
  &quot;browser&quot;: 2,
  &quot;region&quot;: 1,
  &quot;traffic_type&quot;: 1,
  &quot;visitor_type&quot;: &quot;Returning_Visitor&quot;,
  &quot;weekend&quot;: false
}
</code></pre>
<p><strong>Response</strong>:</p>
<pre><code class="language-json">{
  &quot;label&quot;: &quot;YES&quot;,
  &quot;probability&quot;: 0.73,
  &quot;inference_latency_ms&quot;: 0.31,
  &quot;total_latency_ms&quot;: 1.61
}
</code></pre>
<h3 id="52-tracker-api-fastapi">5.2 Tracker API (FastAPI)</h3>
<p><strong>Location</strong>: <code>d:\op_ecom\tracker\</code><br />
<strong>Port</strong>: 8001<br />
<strong>Database</strong>: MariaDB (port 3307)</p>
<h4 id="file-structure_1">File Structure</h4>
<pre><code>tracker/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â”œâ”€â”€ database.py       # SQLAlchemy connection
â”‚   â”œâ”€â”€ models.py         # ORM models
â”‚   â”œâ”€â”€ schemas.py        # Pydantic schemas
â”‚   â”œâ”€â”€ tracker_router.py # Tracking endpoints
â”‚   â””â”€â”€ admin_router.py   # Admin endpoints
â”œâ”€â”€ database/
â”‚   â””â”€â”€ schema.sql        # MariaDB schema
â”œâ”€â”€ static/
â”‚   â””â”€â”€ tracker.js        # JavaScript client
â””â”€â”€ requirements.txt
</code></pre>
<h4 id="tracker-endpoints">Tracker Endpoints</h4>
<table>
<thead>
<tr>
<th>Endpoint</th>
<th>Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>/tracker/session/start</code></td>
<td>POST</td>
<td>Start session</td>
</tr>
<tr>
<td><code>/tracker/session/end</code></td>
<td>POST</td>
<td>End session</td>
</tr>
<tr>
<td><code>/tracker/pageview</code></td>
<td>POST</td>
<td>Log page visit</td>
</tr>
<tr>
<td><code>/tracker/event</code></td>
<td>POST</td>
<td>Custom event</td>
</tr>
<tr>
<td><code>/tracker/purchase</code></td>
<td>POST</td>
<td>Mark conversion</td>
</tr>
<tr>
<td><code>/admin/sessions</code></td>
<td>GET</td>
<td>List sessions</td>
</tr>
<tr>
<td><code>/admin/sessions/{id}</code></td>
<td>GET</td>
<td>Session detail</td>
</tr>
<tr>
<td><code>/admin/export</code></td>
<td>GET</td>
<td>CSV download</td>
</tr>
<tr>
<td><code>/admin/stats</code></td>
<td>GET</td>
<td>Statistics</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="6-frontend-application">6. Frontend Application</h2>
<h3 id="61-prediction-ui-nextjs">6.1 Prediction UI (Next.js)</h3>
<p><strong>Location</strong>: <code>d:\op_ecom\frontend\</code><br />
<strong>Port</strong>: 3000<br />
<strong>Theme</strong>: Lapis Lazuli (Ù„Ø§Ø¬ÙˆØ±Ø¯ÛŒ)</p>
<h4 id="features">Features</h4>
<ul>
<li>Interactive form for all 17 features</li>
<li>Real-time prediction display</li>
<li>Probability gauge visualization</li>
<li>Inference latency display</li>
<li>Responsive design</li>
</ul>
<h3 id="62-demo-e-commerce-site-vite">6.2 Demo E-commerce Site (Vite)</h3>
<p><strong>Location</strong>: <code>d:\op_ecom\tracker-demo\</code><br />
<strong>Port</strong>: 5173</p>
<h4 id="pages">Pages</h4>
<table>
<thead>
<tr>
<th>Page</th>
<th>Type</th>
<th>Tracker Category</th>
</tr>
</thead>
<tbody>
<tr>
<td>Home</td>
<td>Landing</td>
<td>Session Start</td>
</tr>
<tr>
<td>Products</td>
<td>Listing</td>
<td>ProductRelated</td>
</tr>
<tr>
<td>Product Detail</td>
<td>Detail</td>
<td>ProductRelated</td>
</tr>
<tr>
<td>About</td>
<td>Info</td>
<td>Informational</td>
</tr>
<tr>
<td>Cart</td>
<td>Admin</td>
<td>Administrative</td>
</tr>
<tr>
<td>Checkout</td>
<td>Admin</td>
<td>Administrative</td>
</tr>
<tr>
<td>Success</td>
<td>Conversion</td>
<td>Revenue=TRUE</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="7-analytics-tracker-system">7. Analytics Tracker System</h2>
<h3 id="71-architecture-overview">7.1 Architecture Overview</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Browser  â”‚â”€â”€â”€â”€â–¶â”‚  tracker.js     â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI        â”‚
â”‚   (ShopDemo)    â”‚     â”‚  (JavaScript)   â”‚     â”‚  (Port 8001)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚    MariaDB      â”‚
                                                â”‚   (Port 3307)   â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚   CSV Export    â”‚
                                                â”‚  (UCI Format)   â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="72-database-schema">7.2 Database Schema</h3>
<h4 id="sessions-table">Sessions Table</h4>
<pre><code class="language-sql">CREATE TABLE sessions (
    id INT AUTO_INCREMENT PRIMARY KEY,
    session_id VARCHAR(64) UNIQUE,
    visitor_type ENUM('New_Visitor', 'Returning_Visitor', 'Other'),
    browser VARCHAR(50),
    operating_system VARCHAR(50),
    region INT,
    traffic_type INT,
    is_weekend BOOLEAN,
    month VARCHAR(10),
    special_day FLOAT DEFAULT 0,
    started_at TIMESTAMP,
    ended_at TIMESTAMP,
    revenue BOOLEAN DEFAULT FALSE,
    -- Aggregated metrics
    administrative_count INT DEFAULT 0,
    administrative_duration FLOAT DEFAULT 0,
    informational_count INT DEFAULT 0,
    informational_duration FLOAT DEFAULT 0,
    product_related_count INT DEFAULT 0,
    product_related_duration FLOAT DEFAULT 0,
    bounce_rates FLOAT DEFAULT 0,
    exit_rates FLOAT DEFAULT 0,
    page_values FLOAT DEFAULT 0
);
</code></pre>
<h4 id="page-views-table">Page Views Table</h4>
<pre><code class="language-sql">CREATE TABLE page_views (
    id INT AUTO_INCREMENT PRIMARY KEY,
    session_id VARCHAR(64),
    page_type ENUM('Administrative', 'Informational', 'ProductRelated'),
    page_url VARCHAR(500),
    duration_seconds FLOAT,
    is_bounce BOOLEAN,
    is_exit BOOLEAN,
    page_value FLOAT,
    viewed_at TIMESTAMP
);
</code></pre>
<h3 id="73-javascript-tracker">7.3 JavaScript Tracker</h3>
<pre><code class="language-javascript">// Integration example
&lt;script src=&quot;http://localhost:8001/static/tracker.js&quot; 
        data-api=&quot;http://localhost:8001&quot;&gt;&lt;/script&gt;

// Manual events
window.opEcomTracker.trackEvent('click', 'button', 'add_to_cart');
window.opEcomTracker.trackPurchase(99.99);
</code></pre>
<hr />
<h2 id="8-performance-benchmarks">8. Performance Benchmarks</h2>
<h3 id="81-latency-breakdown">8.1 Latency Breakdown</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Mean</th>
<th>p50</th>
<th>p95</th>
<th>p99</th>
</tr>
</thead>
<tbody>
<tr>
<td>Preprocessing</td>
<td>1.30ms</td>
<td>1.10ms</td>
<td>2.50ms</td>
<td>3.80ms</td>
</tr>
<tr>
<td><strong>ONNX Inference</strong></td>
<td><strong>0.31ms</strong></td>
<td><strong>0.28ms</strong></td>
<td><strong>0.71ms</strong></td>
<td><strong>1.20ms</strong></td>
</tr>
<tr>
<td>Postprocessing</td>
<td>0.05ms</td>
<td>0.04ms</td>
<td>0.08ms</td>
<td>0.12ms</td>
</tr>
<tr>
<td><strong>Total API</strong></td>
<td><strong>1.61ms</strong></td>
<td><strong>1.42ms</strong></td>
<td><strong>3.21ms</strong></td>
<td><strong>5.12ms</strong></td>
</tr>
</tbody>
</table>
<h3 id="82-throughput">8.2 Throughput</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Requests/second (single thread)</td>
<td>~620</td>
</tr>
<tr>
<td>Requests/second (4 workers)</td>
<td>~2,400</td>
</tr>
<tr>
<td>Memory footprint</td>
<td>~150MB</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="9-deployment-guide">9. Deployment Guide</h2>
<h3 id="91-quick-start-docker">9.1 Quick Start (Docker)</h3>
<pre><code class="language-bash"># Clone repository
git clone &lt;repository&gt;
cd op_ecom

# Start all services
docker-compose up --build
</code></pre>
<h3 id="92-manual-setup">9.2 Manual Setup</h3>
<pre><code class="language-bash"># Backend
cd backend
pip install -r requirements.txt
uvicorn app.main:app --port 8000

# Tracker
cd tracker
pip install -r requirements.txt
uvicorn app.main:app --port 8001

# Frontend
cd frontend
npm install
npm run dev

# Demo Site
cd tracker-demo
npm install
npm run dev
</code></pre>
<h3 id="93-service-urls">9.3 Service URLs</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Prediction API</td>
<td>http://localhost:8000</td>
</tr>
<tr>
<td>Prediction Docs</td>
<td>http://localhost:8000/docs</td>
</tr>
<tr>
<td>Tracker API</td>
<td>http://localhost:8001</td>
</tr>
<tr>
<td>Tracker Docs</td>
<td>http://localhost:8001/docs</td>
</tr>
<tr>
<td>Frontend UI</td>
<td>http://localhost:3000</td>
</tr>
<tr>
<td>Demo E-commerce</td>
<td>http://localhost:5173</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="10-future-work">10. Future Work</h2>
<h3 id="101-short-term-improvements">10.1 Short-term Improvements</h3>
<ul>
<li><strong>A/B Testing</strong>: Deploy model variants to measure real-world lift</li>
<li><strong>Model Monitoring</strong>: Track prediction distribution drift</li>
<li><strong>Batch Inference</strong>: Support bulk predictions for offline scoring</li>
</ul>
<h3 id="102-long-term-enhancements">10.2 Long-term Enhancements</h3>
<ul>
<li><strong>Edge Deployment</strong>: Compile to WebAssembly for browser execution</li>
<li><strong>Automated Retraining</strong>: Pipeline for continuous learning</li>
<li><strong>Feature Store</strong>: Centralized feature management</li>
</ul>
<hr />
<h2 id="11-conclusion">11. Conclusion</h2>
<p>The OP-ECOM project successfully demonstrates a complete machine learning system from data to deployment. Key achievements include:</p>
<ol>
<li><strong>High Accuracy</strong>: 0.923 AUC-ROC with 88.6% precision on top leads</li>
<li><strong>Low Latency</strong>: 0.31ms inference using ONNX optimization</li>
<li><strong>Full Stack</strong>: Complete web application with modern UI</li>
<li><strong>Self-Hosted Analytics</strong>: Custom tracker for data collection</li>
<li><strong>Production Ready</strong>: Docker deployment with documentation</li>
</ol>
<p>The system proves that deep learning can meet industrial latency requirements while maintaining state-of-the-art accuracy for e-commerce conversion prediction.</p>
<hr />
<h2 id="appendix">Appendix</h2>
<h3 id="a-project-structure">A. Project Structure</h3>
<pre><code>op_ecom/
â”œâ”€â”€ backend/              # Prediction API (FastAPI)
â”œâ”€â”€ frontend/             # Next.js UI
â”œâ”€â”€ tracker/              # Analytics API (FastAPI)
â”œâ”€â”€ tracker-demo/         # Demo E-commerce (Vite)
â”œâ”€â”€ notebooks/            # Training scripts
â”œâ”€â”€ reports/              # Metrics and benchmarks
â”œâ”€â”€ docker-compose.yml    # Orchestration
â””â”€â”€ README.md             # Documentation
</code></pre>
<h3 id="b-technologies-used">B. Technologies Used</h3>
<table>
<thead>
<tr>
<th>Layer</th>
<th>Technology</th>
</tr>
</thead>
<tbody>
<tr>
<td>ML Framework</td>
<td>PyTorch, Scikit-learn</td>
</tr>
<tr>
<td>Optimization</td>
<td>ONNX Runtime</td>
</tr>
<tr>
<td>Backend</td>
<td>FastAPI, Pydantic, SQLAlchemy</td>
</tr>
<tr>
<td>Database</td>
<td>MariaDB</td>
</tr>
<tr>
<td>Frontend</td>
<td>Next.js, Vite, Tailwind CSS</td>
</tr>
<tr>
<td>Deployment</td>
<td>Docker, Docker Compose</td>
</tr>
</tbody>
</table>
<h3 id="c-references">C. References</h3>
<ol>
<li>UCI Machine Learning Repository - Online Shoppers Intention Dataset</li>
<li>TabM: Advancing Tabular Deep Learning with Multiplicative Net</li>
<li>ONNX Runtime Documentation</li>
<li>FastAPI Documentation</li>
</ol>
<hr />
<p><em>Report generated on January 29, 2026</em><br />
<em>OP-ECOM Project - Complete Technical Documentation</em></p>
</body>
</html>
