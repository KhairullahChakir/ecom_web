{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 2: Advanced Deep Learning Model Suite\n",
                "\n",
                "In this notebook, we benchmark three state-of-the-art neural network architectures for tabular data to find the best balance of accuracy and efficiency.\n",
                "\n",
                "### üèÜ The Contenders:\n",
                "1. **DeepFM (Deep Factorization Machine)**: Combines explicit high-order feature interactions (Neural Network) with low-order interactions (Factorization Machine). Great for capturing user behavior patterns.\n",
                "2. **TabM (Tabular Mini-Ensemble)**: A unified neural network that acts like an efficient ensemble. We use `K=4` ensemble heads for speed.\n",
                "3. **FT-Transformer (feature Tokenizer + Transformer)**: Adapts the \"Attention\" mechanism from ChatGPT/BERT to tabular features. Often provides SOTA accuracy but is computationally heavier.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üî• Using Device: cpu\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.metrics import roc_auc_score, f1_score\n",
                "import matplotlib.pyplot as plt\n",
                "import time\n",
                "import os\n",
                "import json\n",
                "\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"üî• Using Device: {DEVICE}\")\n",
                "\n",
                "# Config\n",
                "DATA_PATH = \"../data/raw/online_shoppers_intention.csv\"\n",
                "MODELS_PATH = \"../backend/models\"\n",
                "REPORTS_PATH = \"../reports/metrics\"\n",
                "os.makedirs(MODELS_PATH, exist_ok=True)\n",
                "os.makedirs(REPORTS_PATH, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Pipeline (Categorical Embeddings)\n",
                "To give DeepFM and Transformers a fair chance, we must treat Categorical variables (Month, VisitorType, etc.) as **Embeddings**, not just numbers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Data Loaded. Train: 9864, Val: 1233, Test: 1233\n",
                        "   Categorical Features: 7 (Dims: [10, 3, 2, 8, 13, 9, 20])\n",
                        "   Numerical Features: 10\n"
                    ]
                }
            ],
            "source": [
                "def load_and_preprocess():\n",
                "    df = pd.read_csv(DATA_PATH)\n",
                "    \n",
                "    # Target\n",
                "    y = df['Revenue'].astype(int).values\n",
                "    \n",
                "    # Feature Engineering / Definition\n",
                "    cat_cols = ['Month', 'VisitorType', 'Weekend', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'SpecialDay']\n",
                "    # Ensure SpecialDay is treated as category or float? Let's treat as simple num for now unless cardinality is low.\n",
                "    # Actually 'SpecialDay' is float (0.0, 0.2...) let's keep it num. \n",
                "    cat_cols = ['Month', 'VisitorType', 'Weekend', 'OperatingSystems', 'Browser', 'Region', 'TrafficType']\n",
                "    \n",
                "    num_cols = [c for c in df.columns if c not in cat_cols and c != 'Revenue']\n",
                "    \n",
                "    # 1. Process Categorical (Label Encoding for Embeddings)\n",
                "    X_cat = np.zeros((len(df), len(cat_cols)), dtype=np.int64)\n",
                "    cat_dims = [] # To store cardinality of each feature\n",
                "    \n",
                "    for i, col in enumerate(cat_cols):\n",
                "        le = LabelEncoder()\n",
                "        X_cat[:, i] = le.fit_transform(df[col].astype(str))\n",
                "        cat_dims.append(len(le.classes_))\n",
                "        \n",
                "    # 2. Process Numerical (Standard Scaling)\n",
                "    scaler = StandardScaler()\n",
                "    X_num = scaler.fit_transform(df[num_cols]).astype(np.float32)\n",
                "    \n",
                "    # Split\n",
                "    X_cat_train, X_cat_temp, X_num_train, X_num_temp, y_train, y_temp = train_test_split(\n",
                "        X_cat, X_num, y, test_size=0.2, random_state=42, stratify=y\n",
                "    )\n",
                "    X_cat_val, X_cat_test, X_num_val, X_num_test, y_val, y_test = train_test_split(\n",
                "        X_cat_temp, X_num_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
                "    )\n",
                "    \n",
                "    data = {\n",
                "        'train': (torch.tensor(X_cat_train), torch.tensor(X_num_train), torch.tensor(y_train, dtype=torch.float32)),\n",
                "        'val': (torch.tensor(X_cat_val), torch.tensor(X_num_val), torch.tensor(y_val, dtype=torch.float32)),\n",
                "        'test': (torch.tensor(X_cat_test), torch.tensor(X_num_test), torch.tensor(y_test, dtype=torch.float32)),\n",
                "        'cat_dims': cat_dims,\n",
                "        'num_dim': X_num.shape[1],\n",
                "        'cat_cols': cat_cols,\n",
                "        'num_cols': num_cols\n",
                "    }\n",
                "    \n",
                "    print(f\"‚úÖ Data Loaded. Train: {len(y_train)}, Val: {len(y_val)}, Test: {len(y_test)}\")\n",
                "    print(f\"   Categorical Features: {len(cat_cols)} (Dims: {cat_dims})\")\n",
                "    print(f\"   Numerical Features: {len(num_cols)}\")\n",
                "    \n",
                "    return data\n",
                "\n",
                "full_data = load_and_preprocess()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Architectures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Model Architectures Defined.\n"
                    ]
                }
            ],
            "source": [
                "class FeatureEmbedding(nn.Module):\n",
                "    \"\"\"Helper to embed categorical features\"\"\"\n",
                "    def __init__(self, cat_dims, embed_dim):\n",
                "        super().__init__()\n",
                "        self.embeddings = nn.ModuleList([\n",
                "            nn.Embedding(num_embeddings=d, embedding_dim=embed_dim) for d in cat_dims\n",
                "        ])\n",
                "        \n",
                "    def forward(self, x_cat):\n",
                "        # x_cat: [Batch, n_cat]\n",
                "        # Output: [Batch, n_cat, embed_dim]\n",
                "        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
                "        return torch.stack(embedded, dim=1)\n",
                "\n",
                "# -----------------------------------------------------\n",
                "# 1. DeepFM\n",
                "# -----------------------------------------------------\n",
                "class DeepFM(nn.Module):\n",
                "    def __init__(self, cat_dims, num_dim, embed_dim=16, hidden_dims=[128, 64]):\n",
                "        super().__init__()\n",
                "        self.embedding = FeatureEmbedding(cat_dims, embed_dim)\n",
                "        \n",
                "        # Linear Part (FM w0 + w1*x)\n",
                "        # For simplicity in DeepFM, the \"Linear\" part is often just a dense layer over raw features \n",
                "        # or embeddings. We'll project continuous to embed_dim too for the interaction part.\n",
                "        self.num_proj = nn.Linear(1, embed_dim)\n",
                "        \n",
                "        total_input_dim = (len(cat_dims) + num_dim) * embed_dim\n",
                "        \n",
                "        # Deep Part (MLP)\n",
                "        layers = []\n",
                "        curr_dim = total_input_dim\n",
                "        for h in hidden_dims:\n",
                "            layers.append(nn.Linear(curr_dim, h))\n",
                "            layers.append(nn.BatchNorm1d(h))\n",
                "            layers.append(nn.ReLU())\n",
                "            layers.append(nn.Dropout(0.2))\n",
                "            curr_dim = h\n",
                "        layers.append(nn.Linear(curr_dim, 1))\n",
                "        self.mlp = nn.Sequential(*layers)\n",
                "        \n",
                "        # FM Part (pair-wise dot products)\n",
                "        # Output is scaler sum of all dot products\n",
                "        \n",
                "    def forward(self, x_cat, x_num):\n",
                "        # Embed Categorical: [B, n_cat, E]\n",
                "        emb_cat = self.embedding(x_cat)\n",
                "        \n",
                "        # Embed Numerical: [B, n_num, 1] -> [B, n_num, E]\n",
                "        # Simple approach: Treat each float as a weight for a shared embedding vector or project it\n",
                "        # Here we just project independent scalars to vectors\n",
                "        b, n = x_num.shape\n",
                "        x_num_unsqueezed = x_num.unsqueeze(-1) # [B, n_num, 1]\n",
                "        emb_num = self.num_proj(x_num_unsqueezed) # [B, n_num, E]\n",
                "        \n",
                "        # Concatenate all fields for FM interactions: [B, n_features, E]\n",
                "        all_emb = torch.cat([emb_cat, emb_num], dim=1)\n",
                "        \n",
                "        # --- FM Component ---\n",
                "        # sum_square = (sum(vi*xi))^2\n",
                "        sum_of_vectors = torch.sum(all_emb, dim=1) # [B, E]\n",
                "        sum_square = sum_of_vectors * sum_of_vectors\n",
                "        \n",
                "        # square_sum = sum((vi*xi)^2)\n",
                "        square_of_vectors = all_emb * all_emb\n",
                "        square_sum = torch.sum(square_of_vectors, dim=1) # [B, E]\n",
                "        \n",
                "        # bit-wise subtract, then sum over embedding dim\n",
                "        fm_out = 0.5 * torch.sum(sum_square - square_sum, dim=1, keepdim=True) # [B, 1]\n",
                "        \n",
                "        # --- Deep Component ---\n",
                "        dnn_in = all_emb.view(b, -1) # Flatten\n",
                "        dnn_out = self.mlp(dnn_in)\n",
                "        \n",
                "        # Combine\n",
                "        return dnn_out + fm_out\n",
                "\n",
                "# -----------------------------------------------------\n",
                "# 2. TabM (Improved)\n",
                "# -----------------------------------------------------\n",
                "class TabM_K4(nn.Module):\n",
                "    def __init__(self, cat_dims, num_dim, hidden_dim=128, n_ensemble=4):\n",
                "        super().__init__()\n",
                "        # For TabM, we usually concat one-hot encoded cats and raw nums\n",
                "        # But to be fair to comparison, we can flatten embeddings\n",
                "        self.embedding = FeatureEmbedding(cat_dims, embed_dim=4) # Small embed for TabM\n",
                "        input_dim = (len(cat_dims) * 4) + num_dim\n",
                "        \n",
                "        self.bn_in = nn.BatchNorm1d(input_dim)\n",
                "        \n",
                "        # Original TabM Logic: Ensemble of efficient blocks\n",
                "        self.ensemble_blocks = nn.ModuleList([\n",
                "            nn.Sequential(\n",
                "                nn.Linear(input_dim, hidden_dim),\n",
                "                nn.BatchNorm1d(hidden_dim),\n",
                "                nn.GELU(),\n",
                "                nn.Dropout(0.1),\n",
                "                nn.Linear(hidden_dim, hidden_dim),\n",
                "                nn.BatchNorm1d(hidden_dim),\n",
                "                nn.GELU(),\n",
                "            ) for _ in range(n_ensemble)\n",
                "        ])\n",
                "        self.heads = nn.ModuleList([\n",
                "            nn.Linear(hidden_dim, 1) for _ in range(n_ensemble)\n",
                "        ])\n",
                "        \n",
                "    def forward(self, x_cat, x_num):\n",
                "        emb_cat = self.embedding(x_cat).flatten(1)\n",
                "        x_in = torch.cat([emb_cat, x_num], dim=1)\n",
                "        x_in = self.bn_in(x_in)\n",
                "        \n",
                "        outputs = [head(block(x_in)) for block, head in zip(self.ensemble_blocks, self.heads)]\n",
                "        stacked = torch.stack(outputs, dim=0)\n",
                "        return stacked.mean(dim=0)\n",
                "\n",
                "# -----------------------------------------------------\n",
                "# 3. FT-Transformer\n",
                "# -----------------------------------------------------\n",
                "class FTTransformer(nn.Module):\n",
                "    def __init__(self, cat_dims, num_dim, embed_dim=32, depth=3, heads=4):\n",
                "        super().__init__()\n",
                "        self.embedding = FeatureEmbedding(cat_dims, embed_dim)\n",
                "        self.num_proj = nn.Linear(1, embed_dim)\n",
                "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
                "        \n",
                "        encoder_layer = nn.TransformerEncoderLayer(\n",
                "            d_model=embed_dim, \n",
                "            nhead=heads, \n",
                "            dim_feedforward=embed_dim*2, \n",
                "            dropout=0.1,\n",
                "            activation='gelu',\n",
                "            batch_first=True\n",
                "        )\n",
                "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
                "        self.head = nn.Linear(embed_dim, 1)\n",
                "        \n",
                "    def forward(self, x_cat, x_num):\n",
                "        b = x_cat.shape[0]\n",
                "        emb_cat = self.embedding(x_cat)\n",
                "        emb_num = self.num_proj(x_num.unsqueeze(-1))\n",
                "        \n",
                "        # [B, N_features, E]\n",
                "        x = torch.cat([emb_cat, emb_num], dim=1)\n",
                "        \n",
                "        # Add CLS token\n",
                "        cls_tokens = self.cls_token.expand(b, -1, -1)\n",
                "        x = torch.cat([cls_tokens, x], dim=1)\n",
                "        \n",
                "        # Transformer Pass\n",
                "        x = self.transformer(x)\n",
                "        \n",
                "        # Predict from CLS token\n",
                "        cls_out = x[:, 0, :]\n",
                "        return self.head(cls_out)\n",
                "\n",
                "print(\"‚úÖ Model Architectures Defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üöÄ Training DeepFM...\n",
                        "  Epoch 5: Loss = 88.9093, Val AUC = 0.4945\n",
                        "  Epoch 10: Loss = 9.8193, Val AUC = 0.6630\n",
                        "  Epoch 15: Loss = 2.5015, Val AUC = 0.6992\n",
                        "  Epoch 20: Loss = 1.9703, Val AUC = 0.7568\n",
                        "  Epoch 25: Loss = 1.7707, Val AUC = 0.7642\n",
                        "  Epoch 30: Loss = 1.7418, Val AUC = 0.7623\n",
                        "üèÅ Finished DeepFM. Best Val AUC: 0.7678. Time: 17.4s\n",
                        "\n",
                        "üöÄ Training TabM_K4...\n",
                        "  Epoch 5: Loss = 0.2303, Val AUC = 0.9144\n",
                        "  Epoch 10: Loss = 0.2100, Val AUC = 0.9214\n",
                        "  Epoch 15: Loss = 0.1912, Val AUC = 0.9222\n",
                        "  Epoch 20: Loss = 0.1782, Val AUC = 0.9208\n",
                        "  Epoch 25: Loss = 0.1689, Val AUC = 0.9182\n",
                        "  Epoch 30: Loss = 0.1658, Val AUC = 0.9181\n",
                        "üèÅ Finished TabM_K4. Best Val AUC: 0.9231. Time: 32.3s\n",
                        "\n",
                        "üöÄ Training FT-Transformer...\n",
                        "  Epoch 5: Loss = 0.3819, Val AUC = 0.7461\n",
                        "  Epoch 10: Loss = 0.3659, Val AUC = 0.7664\n",
                        "  Epoch 15: Loss = 0.3614, Val AUC = 0.7671\n",
                        "  Epoch 20: Loss = 0.3560, Val AUC = 0.7670\n",
                        "üèÅ Finished FT-Transformer. Best Val AUC: 0.7686. Time: 115.7s\n"
                    ]
                }
            ],
            "source": [
                "def train_model(model, name, epochs=30, batch_size=256):\n",
                "    start_time = time.time()\n",
                "    model = model.to(DEVICE)\n",
                "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
                "    criterion = nn.BCEWithLogitsLoss()\n",
                "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
                "    \n",
                "    # Unwrap data\n",
                "    X_c_tr, X_n_tr, y_tr = full_data['train']\n",
                "    X_c_val, X_n_val, y_val = full_data['val']\n",
                "    \n",
                "    dataset = TensorDataset(X_c_tr, X_n_tr, y_tr)\n",
                "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
                "    \n",
                "    best_auc = 0\n",
                "    history = []\n",
                "    \n",
                "    print(f\"\\nüöÄ Training {name}...\")\n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        avg_loss = 0\n",
                "        for xc, xn, y in loader:\n",
                "            xc, xn, y = xc.to(DEVICE), xn.to(DEVICE), y.to(DEVICE)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            out = model(xc, xn).squeeze()\n",
                "            loss = criterion(out, y)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            avg_loss += loss.item()\n",
                "            \n",
                "        scheduler.step()\n",
                "        \n",
                "        # Validation\n",
                "        model.eval()\n",
                "        with torch.no_grad():\n",
                "            val_out = model(X_c_val.to(DEVICE), X_n_val.to(DEVICE)).squeeze()\n",
                "            val_probs = torch.sigmoid(val_out).cpu().numpy()\n",
                "            auc = roc_auc_score(y_val.numpy(), val_probs)\n",
                "            \n",
                "        if auc > best_auc:\n",
                "            best_auc = auc\n",
                "            torch.save(model.state_dict(), f\"{MODELS_PATH}/{name.lower()}.pt\")\n",
                "            \n",
                "        if (epoch+1) % 5 == 0:\n",
                "            print(f\"  Epoch {epoch+1}: Loss = {avg_loss/len(loader):.4f}, Val AUC = {auc:.4f}\")\n",
                "            \n",
                "    training_time = time.time() - start_time\n",
                "    print(f\"üèÅ Finished {name}. Best Val AUC: {best_auc:.4f}. Time: {training_time:.1f}s\")\n",
                "    \n",
                "    return best_auc, training_time\n",
                "\n",
                "cat_dims = full_data['cat_dims']\n",
                "num_dim = full_data['num_dim']\n",
                "\n",
                "results = {}\n",
                "\n",
                "# 1. Train DeepFM\n",
                "model_dfm = DeepFM(cat_dims, num_dim)\n",
                "auc_dfm, time_dfm = train_model(model_dfm, \"DeepFM\")\n",
                "results['DeepFM'] = {'AUC': auc_dfm, 'Time': time_dfm}\n",
                "\n",
                "# 2. Train TabM (K=4)\n",
                "model_tabm = TabM_K4(cat_dims, num_dim, n_ensemble=4)\n",
                "auc_tabm, time_tabm = train_model(model_tabm, \"TabM_K4\")\n",
                "results['TabM_K4'] = {'AUC': auc_tabm, 'Time': time_tabm}\n",
                "\n",
                "# 3. Train FT-Transformer\n",
                "model_ft = FTTransformer(cat_dims, num_dim)\n",
                "auc_ft, time_ft = train_model(model_ft, \"FT-Transformer\", epochs=20) # Transformers train slower\n",
                "results['FT-Transformer'] = {'AUC': auc_ft, 'Time': time_ft}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "========================================\n",
                        "Model                AUC        Train Time\n",
                        "----------------------------------------\n",
                        "DeepFM               0.7678     17.4s\n",
                        "TabM_K4              0.9231     32.3s\n",
                        "FT-Transformer       0.7686     115.7s\n",
                        "========================================\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*40)\n",
                "print(f\"{'Model':<20} {'AUC':<10} {'Train Time':<10}\")\n",
                "print(\"-\"*40)\n",
                "for name, res in results.items():\n",
                "    print(f\"{name:<20} {res['AUC']:.4f}     {res['Time']:.1f}s\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# Save Benchmark\n",
                "with open(f\"{REPORTS_PATH}/deep_learning_benchmark.json\", \"w\") as f:\n",
                "    json.dump(results, f, indent=4)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
