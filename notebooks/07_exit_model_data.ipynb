{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f1f9e1",
   "metadata": {},
   "source": [
    "# Phase 20: Exit Model (Model 2) - Data Pre-processing\n",
    "=====================================================\n",
    "This notebook transforms the raw RetailRocket `events.csv` dataset into sequential clickstream data (windowed sequences) used to train the Abandonment Prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f1f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from: ../scripts/data\\events.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths relative to notebooks/ directory\n",
    "DATA_DIR = \"../scripts/data\"\n",
    "INPUT_PATH = os.path.join(DATA_DIR, \"events.csv\")\n",
    "OUTPUT_DIR = \"../data/processed\"\n",
    "\n",
    "print(f\"Loading raw data from: {INPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d1d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2,756,101 events.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(INPUT_PATH):\n",
    "    print(f\"❌ Error: events.csv not found at {INPUT_PATH}.\")\n",
    "else:\n",
    "    df = pd.read_csv(INPUT_PATH)\n",
    "    print(f\"✅ Loaded {len(df):,} events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m1m1m1m1",
   "metadata": {},
   "source": [
    "### 1. Sequential Mapping\n",
    "We map RetailRocket event types to indices used by the model embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c1c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_TO_PAGE = {\n",
    "    'view': 1,           # Product view\n",
    "    'addtocart': 2,      # Cart operation\n",
    "    'transaction': 3     # Purchase (completed)\n",
    "}\n",
    "\n",
    "df['page_type'] = df['event'].map(EVENT_TO_PAGE)\n",
    "df = df.sort_values(['visitorid', 'timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m2m2m2m2",
   "metadata": {},
   "source": [
    "### 2. Sessionization\n",
    "Group clicks into sessions. A new session starts if there's a 30-minute gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "s1s1s1s1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sequences... (This may take a minute)\n",
      "Generated 382,780 sessions.\n"
     ]
    }
   ],
   "source": [
    "def create_sessions(events_df, gap_minutes=30):\n",
    "    gap_ms = gap_minutes * 60 * 1000\n",
    "    sessions = []\n",
    "    session_labels = []\n",
    "    \n",
    "    current_visitor = None\n",
    "    current_session = []\n",
    "    last_ts = None\n",
    "    \n",
    "    print(\"Creating sequences... (This may take a minute)\")\n",
    "    for i, row in events_df.iterrows():\n",
    "        v_id = row['visitorid']\n",
    "        ts = row['timestamp']\n",
    "        pt = row['page_type']\n",
    "        \n",
    "        if v_id != current_visitor or (last_ts and ts - last_ts > gap_ms):\n",
    "            if len(current_session) >= 2:\n",
    "                sessions.append(current_session)\n",
    "                has_tx = any(e[0] == 3 for e in current_session)\n",
    "                session_labels.append(0 if has_tx else 1)\n",
    "            current_session = []\n",
    "            current_visitor = v_id\n",
    "            \n",
    "        current_session.append((pt, ts))\n",
    "        last_ts = ts\n",
    "        \n",
    "    return sessions, session_labels\n",
    "\n",
    "sessions_raw, labels = create_sessions(df)\n",
    "print(f\"Generated {len(sessions_raw):,} sessions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3m3m3m3",
   "metadata": {},
   "source": [
    "### 3. Padding and Output\n",
    "Normalize durations and pad sequences to a fixed length of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "p1p1p1p1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved sequential data to data/processed/\n",
      "Abandonment Rate: 96.4%\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 20\n",
    "X_page = np.zeros((len(sessions_raw), MAX_LEN), dtype=np.int64)\n",
    "X_dur = np.zeros((len(sessions_raw), MAX_LEN), dtype=np.float32)\n",
    "y = np.array(labels, dtype=np.float32)\n",
    "\n",
    "for i, session in enumerate(sessions_raw):\n",
    "    for j in range(min(len(session)-1, MAX_LEN)):\n",
    "        dur = (session[j+1][1] - session[j][1]) / 1000\n",
    "        X_page[i, j] = session[j][0]\n",
    "        X_dur[i, j] = min(dur, 600) / 600.0\n",
    "    # Last page padding index\n",
    "    if len(session) <= MAX_LEN:\n",
    "        X_page[i, len(session)-1] = session[-1][0]\n",
    "        X_dur[i, len(session)-1] = 0.05 # default tiny duration\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "np.save(os.path.join(OUTPUT_DIR, \"X_page_real.npy\"), X_page)\n",
    "np.save(os.path.join(OUTPUT_DIR, \"X_dur_real.npy\"), X_dur)\n",
    "np.save(os.path.join(OUTPUT_DIR, \"y_abandon_real.npy\"), y)\n",
    "\n",
    "print(\"✅ Saved sequential data to data/processed/\")\n",
    "print(f\"Abandonment Rate: {y.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
