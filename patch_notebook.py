import json
import os

NOTEBOOK_PATH = "d:/op_ecom/notebooks/02_tabm_training.ipynb"

def patch_notebook():
    with open(NOTEBOOK_PATH, 'r', encoding='utf-8') as f:
        nb = json.load(f)

    for cell in nb['cells']:
        # Cell 1: Update Imports
        if cell['cell_type'] == 'code' and 'import torch' in "".join(cell['source']):
            new_source = [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import time\n",
                "import os\n",
                "import json\n",
                "\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"ðŸ”¥ Using Device: {DEVICE}\")\n",
                "\n",
                "# Config\n",
                "DATA_PATH = \"../data/raw/online_shoppers_intention.csv\"\n",
                "MODELS_PATH = \"../backend/models\"\n",
                "REPORTS_PATH = \"../reports/metrics\"\n",
                "os.makedirs(MODELS_PATH, exist_ok=True)\n",
                "os.makedirs(REPORTS_PATH, exist_ok=True)"
            ]
            cell['source'] = new_source

        # Cell 4: Update Training Loop & Utilities
        if cell['cell_type'] == 'code' and 'def train_model' in "".join(cell['source']):
            new_source = [
                "def train_model(model, name, epochs=30, batch_size=256):\n",
                "    start_time = time.time()\n",
                "    model = model.to(DEVICE)\n",
                "    \n",
                "    # âš–ï¸ Handle Imbalance (New)\n",
                "    X_c_tr, X_n_tr, y_tr = full_data['train']\n",
                "    X_c_val, X_n_val, y_val = full_data['val']\n",
                "    \n",
                "    pos_counts = (y_tr == 1).sum()\n",
                "    neg_counts = (y_tr == 0).sum()\n",
                "    pos_weight = torch.tensor([neg_counts / pos_counts]).to(DEVICE)\n",
                "    \n",
                "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
                "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) # Balanced Loss\n",
                "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
                "    \n",
                "    dataset = TensorDataset(X_c_tr, X_n_tr, y_tr)\n",
                "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
                "    \n",
                "    best_auc = 0\n",
                "    history = {'train_loss': [], 'val_auc': []}\n",
                "    \n",
                "    print(f\"\\nðŸš€ Training {name} (Balance Weight: {pos_weight.item():.2f})...\")\n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        avg_loss = 0\n",
                "        for xc, xn, y in loader:\n",
                "            xc, xn, y = xc.to(DEVICE), xn.to(DEVICE), y.to(DEVICE)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            out = model(xc, xn).squeeze()\n",
                "            loss = criterion(out, y)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            avg_loss += loss.item()\n",
                "            \n",
                "        scheduler.step()\n",
                "        \n",
                "        # Validation\n",
                "        model.eval()\n",
                "        with torch.no_grad():\n",
                "            val_out = model(X_c_val.to(DEVICE), X_n_val.to(DEVICE)).squeeze()\n",
                "            val_probs = torch.sigmoid(val_out).cpu().numpy()\n",
                "            auc = roc_auc_score(y_val.numpy(), val_probs)\n",
                "            \n",
                "        history['train_loss'].append(avg_loss/len(loader))\n",
                "        history['val_auc'].append(auc)\n",
                "            \n",
                "        if auc > best_auc:\n",
                "            best_auc = auc\n",
                "            torch.save(model.state_dict(), f\"{MODELS_PATH}/{name.lower()}.pt\")\n",
                "            \n",
                "        if (epoch+1) % 5 == 0:\n",
                "            print(f\"  Epoch {epoch+1}: Loss = {avg_loss/len(loader):.4f}, Val AUC = {auc:.4f}\")\n",
                "            \n",
                "    training_time = time.time() - start_time\n",
                "    print(f\"ðŸ Finished {name}. Best Val AUC: {best_auc:.4f}. Time: {training_time:.1f}s\")\n",
                "    \n",
                "    return best_auc, training_time, history\n",
                "\n",
                "def evaluate_and_plot(model, name, history):\n",
                "    # 1. Prediction\n",
                "    X_c_ts, X_n_ts, y_ts = full_data['test']\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        out = model(X_c_ts.to(DEVICE), X_n_ts.to(DEVICE)).squeeze()\n",
                "        probs = torch.sigmoid(out).cpu().numpy()\n",
                "        preds = (probs > 0.5).astype(int)\n",
                "    \n",
                "    y_true = y_ts.numpy()\n",
                "    \n",
                "    # 2. Metrics\n",
                "    res = {\n",
                "        'AUC': roc_auc_score(y_true, probs),\n",
                "        'F1': f1_score(y_true, preds),\n",
                "        'Precision': precision_score(y_true, preds),\n",
                "        'Recall': recall_score(y_true, preds)\n",
                "    }\n",
                "    \n",
                "    # 3. Visualization\n",
                "    plt.figure(figsize=(18, 5))\n",
                "    \n",
                "    # Training Loss/AUC\n",
                "    plt.subplot(1, 4, 1)\n",
                "    plt.plot(history['train_loss'])\n",
                "    plt.title(f'{name} Loss')\n",
                "    \n",
                "    plt.subplot(1, 4, 2)\n",
                "    plt.plot(history['val_auc'], color='orange')\n",
                "    plt.title(f'{name} Val AUC')\n",
                "    \n",
                "    # ROC Curve\n",
                "    plt.subplot(1, 4, 3)\n",
                "    fpr, tpr, _ = roc_curve(y_true, probs)\n",
                "    plt.plot(fpr, tpr, label=f'AUC={res[\"AUC\"]:.4f}')\n",
                "    plt.plot([0,1],[0,1], 'k--')\n",
                "    plt.title(f'{name} ROC')\n",
                "    plt.legend()\n",
                "    \n",
                "    # CM\n",
                "    plt.subplot(1, 4, 4)\n",
                "    cm = confusion_matrix(y_true, preds)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "    plt.title(f'{name} CM')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return res\n",
                "\n",
                "cat_dims = full_data['cat_dims']\n",
                "num_dim = full_data['num_dim']\n",
                "\n",
                "results = {}\n",
                "\n",
                "print(\"ðŸš€ Starting Tournament (Balanced Implementation)...\")\n",
                "\n",
                "# 1. Train DeepFM\n",
                "model_dfm = DeepFM(cat_dims, num_dim)\n",
                "auc_dfm, time_dfm, hist_dfm = train_model(model_dfm, \"DeepFM\")\n",
                "results['DeepFM'] = evaluate_and_plot(model_dfm, \"DeepFM\", hist_dfm)\n",
                "results['DeepFM']['Time'] = time_dfm\n",
                "\n",
                "# 2. Train TabM (K=4)\n",
                "model_tabm = TabM_K4(cat_dims, num_dim, n_ensemble=4)\n",
                "auc_tabm, time_tabm, hist_tabm = train_model(model_tabm, \"TabM_K4\")\n",
                "results['TabM_K4'] = evaluate_and_plot(model_tabm, \"TabM_K4\", hist_tabm)\n",
                "results['TabM_K4']['Time'] = time_tabm\n",
                "\n",
                "# 3. Train FT-Transformer\n",
                "model_ft = FTTransformer(cat_dims, num_dim)\n",
                "auc_ft, time_ft, hist_ft = train_model(model_ft, \"FT-Transformer\", epochs=20)\n",
                "results['FT-Transformer'] = evaluate_and_plot(model_ft, \"FT-Transformer\", hist_ft)\n",
                "results['FT-Transformer']['Time'] = time_ft"
            ]
            cell['source'] = new_source

        # Cell 5: Update Final Comparison Table
        if cell['cell_type'] == 'code' and 'Final Comparison' in "".join(cell.get('source', [])) or (cell['cell_type'] == 'code' and 'print(\"\\n\" + \"=\"*40)' in "".join(cell['source'])):
            new_source = [
                "print(\"\\n\" + \"=\"*90)\n",
                "print(f\"{'Model':<20} {'AUC':<10} {'F1':<10} {'Precision':<10} {'Recall':<10} {'Time':<10}\")\n",
                "print(\"-\"*90)\n",
                "for name, res in results.items():\n",
                "    print(f\"{name:<20} {res['AUC']:.4f}     {res['F1']:.4f}     {res['Precision']:.4f}     {res['Recall']:.4f}     {res['Time']:.1f}s\")\n",
                "print(\"=\"*90)\n",
                "\n",
                "# Save Benchmark\n",
                "with open(f\"{REPORTS_PATH}/deep_learning_benchmark.json\", \"w\") as f:\n",
                "    json.dump(results, f, indent=4)"
            ]
            cell['source'] = new_source

    with open(NOTEBOOK_PATH, 'w', encoding='utf-8') as f:
        json.dump(nb, f, indent=1)
    print("âœ… Notebook patched successfully!")

if __name__ == "__main__":
    patch_notebook()
